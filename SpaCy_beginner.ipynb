{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWlEqKCLu9a2",
        "outputId": "de4bed21-e376-4f8b-9d0a-7c31a3b73cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ-qO5eavwnn",
        "outputId": "084ffaec-ec53-45f3-c30e-a6a1b38b7a86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-03 16:52:40.354736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-03 16:52:42.457000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "ZxaNdDfirccQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOELhyzUIs6H",
        "outputId": "8c309e61-23bc-483f-cbf7-2f1bfbba8396"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/drive/MyDrive/Dataset/wiki_us.txt\", \"r\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "3maHW3SQ2DyO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "x5DkloIX2jHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29445c24-85da-4d5e-a50d-2a749f09b3b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d] The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York.\n",
            "\n",
            "Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago, and European colonization began in the 16th century. The United States emerged from the thirteen British colonies established along the East Coast. Disputes over taxation and political representation with Great Britain led to the American Revolutionary War (1775–1783), which established independence. In the late 18th century, the U.S. began expanding across North America, gradually obtaining new territories, sometimes through war, frequently displacing Native Americans, and admitting new states; by 1848, the United States spanned the continent. Slavery was legal in the southern United States until the second half of the 19th century when the American Civil War led to its abolition. The Spanish–American War and World War I established the U.S. as a world power, a status confirmed by the outcome of World War II.\n",
            "\n",
            "During the Cold War, the United States fought the Korean War and the Vietnam War but avoided direct military conflict with the Soviet Union. The two superpowers competed in the Space Race, culminating in the 1969 spaceflight that first landed humans on the Moon. The Soviet Union's dissolution in 1991 ended the Cold War, leaving the United States as the world's sole superpower.\n",
            "\n",
            "The United States is a federal republic and a representative democracy with three separate branches of government, including a bicameral legislature. It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States, NATO, and other international organizations. It is a permanent member of the United Nations Security Council. Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by centuries of immigration. The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption. However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.\n",
            "\n",
            "The United States is a highly developed country, accounts for approximately a quarter of global GDP, and is the world's largest economy. By value, the United States is the world's largest importer and the second-largest exporter of goods. Although its population is only 4.2% of the world's total, it holds 29.4% of the total wealth in the world, the largest share held by any country. Making up more than a third of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "kE0lVEs6I4NF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))\n",
        "print(len(doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlZvk2KivKM6",
        "outputId": "441a5244-4b70-42ce-e70b-fbfb0347dc9e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3521\n",
            "654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in text[0:10]:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ghs-h9P3wnK5",
        "outputId": "2d8ae7b2-9542-49b0-c3aa-6f9cf1db967d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "U\n",
            "n\n",
            "i\n",
            "t\n",
            "e\n",
            "d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc[0:10]:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKtMw8i9yBfC",
        "outputId": "f5bd7a9b-df6c-4064-ab33-9e394a0daf7c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "United\n",
            "States\n",
            "of\n",
            "America\n",
            "(\n",
            "U.S.A.\n",
            "or\n",
            "USA\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SpaCy automatically detects characters with period like U.S.A.\n",
        "#SpaCy removed the punctuation mark like the parenthesis (U.S.A. or USA) \n",
        "#and treated them as individual characters"
      ],
      "metadata": {
        "id": "67erYevRyNl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If we split tokens by white space separation, it would look something like this"
      ],
      "metadata": {
        "id": "k_bhFkk3_tIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in text.split()[:10]:\n",
        "  print (token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUWLATWHBrBF",
        "outputId": "c9d68dbb-d7ac-44e4-e71c-3f831b17f8d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "United\n",
            "States\n",
            "of\n",
            "America\n",
            "(U.S.A.\n",
            "or\n",
            "USA),\n",
            "commonly\n",
            "known\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Boundary Detection (SBD) in NLP \n",
        "# is identification of sentences ina text.\n",
        "# In english, abbreviation of word is also\n",
        "#demarcated with period punctuation.\n",
        "# So we can't just split and demarcate a sentence\n",
        "# just separated by period."
      ],
      "metadata": {
        "id": "m1SJVpOOEWAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc.sents:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-UiG-26FDFb",
        "outputId": "ac4527c6-ef11-40e8-e86e-02b4a0acf547"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n",
            "It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j]\n",
            "At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d]\n",
            "The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22]\n",
            "With a population of more than 331 million people, it is the third most populous country in the world.\n",
            "The national capital is Washington, D.C., and the most populous city is New York.\n",
            "\n",
            "\n",
            "Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago, and European colonization began in the 16th century.\n",
            "The United States emerged from the thirteen British colonies established along the East Coast.\n",
            "Disputes over taxation and political representation with Great Britain led to the American Revolutionary War (1775–1783), which established independence.\n",
            "In the late 18th century, the U.S. began expanding across North America, gradually obtaining new territories, sometimes through war, frequently displacing Native Americans, and admitting new states; by 1848, the United States spanned the continent.\n",
            "Slavery was legal in the southern United States until the second half of the 19th century when the American Civil War led to its abolition.\n",
            "The Spanish–American War and World War I established the U.S. as a world power, a status confirmed by the outcome of World War II.\n",
            "\n",
            "\n",
            "During the Cold War, the United States fought the Korean War and the Vietnam War but avoided direct military conflict with the Soviet Union.\n",
            "The two superpowers competed in the Space Race, culminating in the 1969 spaceflight that first landed humans on the Moon.\n",
            "The Soviet Union's dissolution in 1991 ended the Cold War, leaving the United States as the world's sole superpower.\n",
            "\n",
            "\n",
            "The United States is a federal republic and a representative democracy with three separate branches of government, including a bicameral legislature.\n",
            "It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States, NATO, and other international organizations.\n",
            "It is a permanent member of the United Nations Security Council.\n",
            "Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by centuries of immigration.\n",
            "The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption.\n",
            "However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.\n",
            "\n",
            "\n",
            "The United States is a highly developed country, accounts for approximately a quarter of global GDP, and is the world's largest economy.\n",
            "By value, the United States is the world's largest importer and the second-largest exporter of goods.\n",
            "Although its population is only 4.2% of the world's total, it holds 29.4% of the total wealth in the world, the largest share held by any country.\n",
            "Making up more than a third of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = list(doc.sents)[0]\n",
        "print(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHU9rzGjM7Cf",
        "outputId": "e47ea40e-bf1f-4d48-89e8-9a6d4c5fc445"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2 = sentence1[2]\n",
        "print (token2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aDpzZeTOFlx",
        "outputId": "df4659f4-a08d-4719-b39d-d0067ca3f96d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "States\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To extract text from token and not the token object\n",
        "token2.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0wNvskaAcm3k",
        "outputId": "4d70d677-a48e-4bd9-ca33-bef1eda5aafc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'States'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#token2 object has attributes\n",
        "#To get the left most token corresponding to token2\n",
        "token2.left_edge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejrg27h7Q75F",
        "outputId": "b89cf530-c627-437b-eb35-677de1bcdaeb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2.right_edge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD7vc6b-daza",
        "outputId": "5c8278fa-7c90-443e-adcc-d7623480553b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "America"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2.ent_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1mLYhCLeC_4",
        "outputId": "cafebb30-1f70-42f7-f416-c450cee051c6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The string corresponding to 384 is\n",
        "token2.ent_type_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vsv2eJ4sgQBy",
        "outputId": "db116858-4f23-4819-fd3f-159f849e94ed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPE means Geo Political Entity"
      ],
      "metadata": {
        "id": "7WxubCVvgYKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iob is a specific kind of Named Entity code\n",
        "#'I' tells that the word States is inside of a large entity.\n",
        "token2.ent_iob_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IgUH8GwegiFo",
        "outputId": "aa1eb1d5-03a1-432b-9d2b-9e4cd86f3143"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemma form or root form of the word\n",
        "token2.lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SfVZHuzKhorC",
        "outputId": "c34b1b20-f233-4b34-b1f1-d4e54876ec56"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'States'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kNyucwBiOi1",
        "outputId": "1adb1b5d-d99f-47ba-83ba-efe97e162987"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence1[12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFxltuXJieM1",
        "outputId": "82c856b0-f988-49a0-b103-12064d11bdb6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "known\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemma form is uninflected verb form of known\n",
        "sentence1[12].lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3XtNDG4rinnI",
        "outputId": "a4f50196-3fa4-4d39-9651-e564e05d57cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'know'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#morphological form of token2 is Singular\n",
        "token2.morph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJwhtR71jhR2",
        "outputId": "88f7e1e3-6574-4df0-a24e-a3a7220ed38e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Number=Sing"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pos is part of speech and PROPN means proper noun\n",
        "token2.pos_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RDAE4P4UnFNi",
        "outputId": "8f46718b-90eb-4c5c-967c-4238a92b93fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PROPN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what role it plays in sentence or dependency relation, here noun subject\n",
        "token2.dep_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZdD07Lz_pbTe",
        "outputId": "813f4259-a29d-4d98-a1ea-42d77b523f18"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nsubj'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Language from doc object\n",
        "token2.lang_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jv7w7ihep6wh",
        "outputId": "bf4b0926-5022-4191-91d7-3b5e47a66ab2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Morphological form of sentence1 is Perfect Past Participle\n",
        "sentence1[12].morph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg3UjSm4kFlw",
        "outputId": "d322a890-86c8-4370-87c7-727d88c28f2c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aspect=Perf|Tense=Past|VerbForm=Part"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parts of speech in SpaCy and dependency parser\n",
        "#Basic semantics of SpaCy\n",
        "txt = \"Mike enjoys playing football.\"\n",
        "doc2 = nlp(txt)\n",
        "print (doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ipgp25ikbgn",
        "outputId": "6266037f-c909-412d-f153-f6c82a5aa962"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mike enjoys playing football.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc2:\n",
        "  print(token.text, token.pos_, token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7V-S38IzN_E",
        "outputId": "498f6e49-2364-4e89-e1ab-4bd80062df8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mike PROPN nsubj\n",
            "enjoys VERB ROOT\n",
            "playing VERB xcomp\n",
            "football NOUN dobj\n",
            ". PUNCT punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To visually see the structure of doc2\n",
        "from spacy import displacy\n",
        "displacy.render(doc2, style=\"dep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "22czZfJEzj0_",
        "outputId": "89392432-a192-4328-f04e-6f2df11cdce3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5662cad356c147d9936bc4dd910acd8e-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mike</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enjoys</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">playing</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">football.</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\\n</text>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-5662cad356c147d9936bc4dd910acd8e-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-5662cad356c147d9936bc4dd910acd8e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-5662cad356c147d9936bc4dd910acd8e-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-5662cad356c147d9936bc4dd910acd8e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-5662cad356c147d9936bc4dd910acd8e-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-5662cad356c147d9936bc4dd910acd8e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n</svg>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Named Entity Recognition or NER\n",
        "#How to iterate over doc object\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AT_HnXd1pA-",
        "outputId": "304d7f19-d979-490b-e042-fe64d6bdd820"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America GPE\n",
            "U.S.A. GPE\n",
            "USA GPE\n",
            "the United States GPE\n",
            "U.S. GPE\n",
            "US GPE\n",
            "America GPE\n",
            "North America LOC\n",
            "50 CARDINAL\n",
            "five CARDINAL\n",
            "326 CARDINAL\n",
            "Indian NORP\n",
            "3.8 million square miles QUANTITY\n",
            "9.8 million square kilometers QUANTITY\n",
            "fourth ORDINAL\n",
            "The United States GPE\n",
            "Canada GPE\n",
            "Mexico GPE\n",
            "Bahamas GPE\n",
            "Cuba GPE\n",
            "more than 331 million CARDINAL\n",
            "third ORDINAL\n",
            "Washington GPE\n",
            "D.C. GPE\n",
            "New York GPE\n",
            "Paleo-Indians NORP\n",
            "Siberia LOC\n",
            "North American NORP\n",
            "at least 12,000 years ago DATE\n",
            "European NORP\n",
            "the 16th century DATE\n",
            "The United States GPE\n",
            "thirteen CARDINAL\n",
            "British NORP\n",
            "the East Coast LOC\n",
            "Great Britain GPE\n",
            "the American Revolutionary War ORG\n",
            "the late 18th century DATE\n",
            "U.S. GPE\n",
            "North America LOC\n",
            "Native Americans NORP\n",
            "1848 DATE\n",
            "the United States GPE\n",
            "United States GPE\n",
            "the second half of the 19th century DATE\n",
            "the American Civil War ORG\n",
            "Spanish NORP\n",
            "World War EVENT\n",
            "U.S. GPE\n",
            "World War II EVENT\n",
            "the Cold War EVENT\n",
            "the United States GPE\n",
            "the Korean War EVENT\n",
            "the Vietnam War EVENT\n",
            "the Soviet Union GPE\n",
            "two CARDINAL\n",
            "the Space Race FAC\n",
            "1969 DATE\n",
            "first ORDINAL\n",
            "The Soviet Union's GPE\n",
            "1991 DATE\n",
            "the Cold War EVENT\n",
            "the United States GPE\n",
            "The United States GPE\n",
            "three CARDINAL\n",
            "the United Nations ORG\n",
            "World Bank ORG\n",
            "International Monetary Fund ORG\n",
            "Organization of American States ORG\n",
            "NATO ORG\n",
            "the United Nations Security Council ORG\n",
            "centuries DATE\n",
            "The United States GPE\n",
            "approximately a quarter DATE\n",
            "the United States GPE\n",
            "second ORDINAL\n",
            "only 4.2% PERCENT\n",
            "29.4% PERCENT\n",
            "more than a third CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SpaCy, Python and ML\n",
        "import spacy"
      ],
      "metadata": {
        "id": "5DP2QN_fCIcO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing spacy medium model as it has word vectors stored within it\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCR6xog1kFqI",
        "outputId": "d9b1fbd5-8c5b-49c4-9594-83e6895f8eb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 02:01:54.064613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word vectors or word embeddings are numerical representations of words in multidimensional space through matrices\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "_aAuYvZ68J0j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnpyIlfiiBDK",
        "outputId": "a208f91b-7ff3-465c-f776-90d65147adf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/drive/MyDrive/Dataset/wiki_us.txt\", \"r\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "ULLpJ7WMfvhy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating doc object\n",
        "doc = nlp(text)\n",
        "sentence1 = list(doc.sents)[0]\n",
        "print(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC6zQAg7izMy",
        "outputId": "01c97f36-c79c-49c4-cb8b-536f32b1abc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How to use word vectors with spacy\n",
        "#Say how the word \"country\" is similar with other words in our model\n",
        "\n",
        "import numpy as np\n",
        "your_word = \"country\"\n",
        "\n",
        "ms = nlp.vocab.vectors.most_similar(\n",
        "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]]), n=10)\n",
        "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
        "distances = ms[2]\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNNBpqlOmMHo",
        "outputId": "ae600acb-c91e-42a0-cbef-7ec73bc806a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['country—0,467', 'nationâ\\x80\\x99s', 'countries-', 'continente', 'Carnations', 'pastille', 'бесплатно', 'Argents', 'Tywysogion', 'Teeters']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking similarity between two sentences\n",
        "doc1 = nlp(\"I like cheeseburgers and fries.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "print (doc1, \"<->\", doc2, doc1.similarity(doc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjpo6wsutgmH",
        "outputId": "730c1ac8-eb71-4984-e009-698995b78219"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like cheeseburgers and fries. <-> Fast food tastes very good. 0.6667528705068858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cheeseburgers = doc1[2]\n",
        "fries = doc1[4]\n",
        "\n",
        "print(cheeseburgers, \"<->\", fries, cheeseburgers.similarity(fries))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57xrSsqm0hah",
        "outputId": "32b939f2-4c10-432b-eb55-78f1619900e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cheeseburgers <-> fries 0.734847903251648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Because of word embedding, apple and banana are in similar cluster of fruit\n",
        "\n",
        "doc3 = nlp(\"I like oranges.\")\n",
        "doc4 = nlp(\"I like apples.\")\n",
        "\n",
        "print (doc3, \"<->\", doc4, doc3.similarity(doc4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4kUA6LZyMlb",
        "outputId": "d7174992-8312-43d1-bc8c-7997732e5586"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like oranges. <-> I like apples. 0.9787321635750837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Spacy Pipeline for NER\n",
        "\n",
        "#Input Sentence -> Entity Ruler -> Entity Linker -> Output (Sentence with Entities Annotated)"
      ],
      "metadata": {
        "id": "ar98_36yz3bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will make a blank spacy pipeline\n",
        "#Creating blank spacy pipeline\n",
        "import spacy\n",
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "D_vqnAZId1fY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentencizer lets you implement a simpler, rule-based strategy that doesn’t require a statistical model to be loaded\n",
        "nlp.add_pipe(\"sentencizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO0fT8xNu_vW",
        "outputId": "01c3478f-dd03-4db3-f552-7f3b86493e6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7f4a2caeb0c0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analyzing pipeline\n",
        "nlp.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLb6eKQvv4Z",
        "outputId": "4e871096-1c7d-4776-e062-c61884670f60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'sentencizer': {'assigns': ['token.is_sent_start', 'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['sents_f', 'sents_p', 'sents_r'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'sentencizer': []},\n",
              " 'attrs': {'token.is_sent_start': {'assigns': ['sentencizer'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['sentencizer'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will now create a more robust pipeline\n",
        "nlp2 = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Wa6EwEemwC3u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wx1xy2XynA9",
        "outputId": "0deebb6c-c468-44cf-ffd2-401b57f15b79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': []},\n",
              " 'attrs': {'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rule based spacy\n",
        "#2 ways to add custom features to spacy language pipeline\n",
        "#1- Rule based approach 2- Machine Learning Approach\n"
      ],
      "metadata": {
        "id": "3pUn_DkdzUr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"West Chestertenfieldville was referenced in Mr. Deeds.\""
      ],
      "metadata": {
        "id": "2lFhZ0OOG5D6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "AkT5wVMlAhAd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the label - We expect the label to be wrong so that we can use ruler to fix it\n",
        "for ent in doc.ents:\n",
        "  print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yK32eqMAwkW",
        "outputId": "fd01120d-9fcf-4ea0-dfea-db99179e8108"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "West Chestertenfieldville GPE\n",
            "Deeds PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruler = nlp.add_pipe(\"entity_ruler\")"
      ],
      "metadata": {
        "id": "M96GERKIEO_8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entity_ruler is added\n",
        "nlp.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgHjXfHoFIq4",
        "outputId": "19f351bb-4830-424c-811d-14e6475322d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': [],\n",
              "  'entity_ruler': []},\n",
              " 'attrs': {'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we will add pattern to the pipeline\n",
        "patterns = [\n",
        "    {\"label\": \"TV Show\", \"pattern\": \"Mr. Deeds\"}\n",
        "]"
      ],
      "metadata": {
        "id": "ocw-6rFaFTm6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "bDhiMrzki5hK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ner comes before entity_ruler in pipeline. Thats why the label is not changed\n",
        "doc2 = nlp(text)\n",
        "for ent in doc2.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhHtHMM5G0Fg",
        "outputId": "f6944fac-800b-4946-acf1-9bcbdc3db56c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "West Chestertenfieldville GPE\n",
            "Deeds PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We have to put our ruler before ner pipeling to reflect the change\n",
        "nlp2 = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "ruler = nlp2.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "\n",
        "ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "EjgwqyjBksY0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp2(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sODZTgaoIad",
        "outputId": "3be22d13-346f-4b2b-d64d-af41805bf8fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "West Chestertenfieldville GPE\n",
            "Mr. Deeds TV Show\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can see Mr. Deeds is now correctly labelled to TV Show\n",
        "#Lets look at nlp2 pipe\n",
        "nlp2.analyze_pipes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TCOypsUorFQ",
        "outputId": "ac1b60cc-3b96-49f7-e40c-559428e136ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'entity_ruler': [],\n",
              "  'ner': []},\n",
              " 'attrs': {'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we see that our entity_ruler is set before ner moodel"
      ],
      "metadata": {
        "id": "PdQkzXgTpPyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spacy Matcher\n",
        "\n",
        "#The key difference between entity ruler and a matcher is how data is extracted\n",
        "\n",
        "#Entity ruler is used when the thing we try to extract is something that has a label corresponds to it within the entity\n",
        "\n",
        "#We will use matcher when something is not an entity type but something that is a structure\n",
        "#within a text that will help us extract information\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2kOUikUcuKA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "nTI37fDxArum"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load small english model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "_yM4WA17Kz4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will try to find email address from text\n",
        "#Say we want to extract everything looking like an email\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LIKE_EMAIL\":True}]\n",
        "matcher.add(\"EMAIL_ADDRESS\", [pattern])"
      ],
      "metadata": {
        "id": "TOmCu4Q_MEV0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"This is an email address: sarhal@yahoo.com\")\n",
        "matches = matcher(doc)"
      ],
      "metadata": {
        "id": "bHOMeJALSPYe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We get a list containing set of tuples with 3 indices\n",
        "#Index 0 is Lexeme, then start token, then end token\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN74g98FS40Y",
        "outputId": "6fd84fc8-b577-41de-b954-1dd5e4e2019d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(16571425990740197027, 6, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will go to NLP vocab where the integer lies and find what it corresponds to\n",
        "#Label we have given is added to nlp vocab with unique lexeme\n",
        "print(nlp.vocab[matches[0][0]].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-EKUToVz7me",
        "outputId": "ad57e764-880b-4d45-bb1e-a6217ef0c0f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMAIL_ADDRESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMFtZaF5SWiN",
        "outputId": "9e467860-2c25-4e9e-eba9-53cb05cfcf26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/drive/MyDrive/Dataset/wiki_mlk.txt\", \"r\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "FQkai2tfOwEK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFIFYyjrTW3K",
        "outputId": "681b3176-e0ff-4888-d4fd-a7885bf76cca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Martin Luther King Jr. (born Michael King Jr.; January 15, 1929 – April 4, 1968) was an American Baptist minister and activist who was one of the most prominent leaders in the civil rights movement from 1955 until his assassination in 1968. A Black church leader and a son of early civil rights activist and minister Martin Luther King Sr., King advanced civil rights for people of color in the United States through nonviolence and civil disobedience. Inspired by his Christian beliefs and the nonviolent activism of Mahatma Gandhi, he led targeted, nonviolent resistance against Jim Crow laws and other forms of discrimination in the United States.\n",
            "\n",
            "King participated in and led marches for the right to vote, desegregation, labor rights, and other civil rights.[1] He oversaw the 1955 Montgomery bus boycott and later became the first president of the Southern Christian Leadership Conference (SCLC). As president of the SCLC, he led the unsuccessful Albany Movement in Albany, Georgia, and helped organize some of the nonviolent 1963 protests in Birmingham, Alabama. King was one of the leaders of the 1963 March on Washington, where he delivered his \"I Have a Dream\" speech on the steps of the Lincoln Memorial. The civil rights movement achieved pivotal legislative gains in the Civil Rights Act of 1964, Voting Rights Act of 1965, and the Fair Housing Act of 1968.\n",
            "\n",
            "The SCLC put into practice the tactics of nonviolent protest with some success by strategically choosing the methods and places in which protests were carried out. There were several dramatic standoffs with segregationist authorities, who frequently responded violently.[2] King was jailed several times. Federal Bureau of Investigation (FBI) director J. Edgar Hoover considered King a radical and made him an object of the FBI's COINTELPRO from 1963 forward. FBI agents investigated him for possible communist ties, spied on his personal life, and secretly recorded him. In 1964, the FBI mailed King a threatening anonymous letter, which he interpreted as an attempt to make him commit suicide.[3]\n",
            "\n",
            "On October 14, 1964, King won the Nobel Peace Prize for combating racial inequality through nonviolent resistance. In 1965, he helped organize two of the three Selma to Montgomery marches. In his final years, he expanded his focus to include opposition towards poverty, capitalism, and the Vietnam War. In 1968, King was planning a national occupation of Washington, D.C., to be called the Poor People's Campaign, when he was assassinated on April 4 in Memphis, Tennessee. His death was followed by national mourning, as well as anger leading to riots in many U.S. cities. King was posthumously awarded the Presidential Medal of Freedom in 1977 and the Congressional Gold Medal in 2003. Martin Luther King Jr. Day was established as a holiday in cities and states throughout the United States beginning in 1971; the federal holiday was first observed in 1986. Hundreds of streets in the U.S. have been renamed in his honor, and King County in Washington was rededicated for him. The Martin Luther King Jr. Memorial on the National Mall in Washington, D.C., was dedicated in 2011.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We will create a new model and grab all proper nouns\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "6NUM01ipTdyT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\"}]\n",
        "matcher.add(\"PROPER_NOUN\", [pattern])\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "  print(match, doc[match[1]:match[2] ])\n",
        "\n",
        "#The lexxim with token extracted is shown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMHtBwalVvh6",
        "outputId": "c43d69ac-72cc-4437-9954-c1400c6135db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111\n",
            "(451313080118390996, 0, 1) Martin\n",
            "(451313080118390996, 1, 2) Luther\n",
            "(451313080118390996, 2, 3) King\n",
            "(451313080118390996, 3, 4) Jr.\n",
            "(451313080118390996, 6, 7) Michael\n",
            "(451313080118390996, 7, 8) King\n",
            "(451313080118390996, 8, 9) Jr.\n",
            "(451313080118390996, 10, 11) January\n",
            "(451313080118390996, 15, 16) April\n",
            "(451313080118390996, 23, 24) Baptist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can make the token multi word\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print(len(matches))\n",
        "for match in matches[:10]:\n",
        "  print(match, doc[match[1]:match[2] ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVDCkcxA21u_",
        "outputId": "20d02774-05f2-4350-8434-fead76ebce65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n",
            "(451313080118390996, 62, 67) Martin Luther King Sr.\n",
            "(451313080118390996, 511, 516) Martin Luther King Jr. Day\n",
            "(451313080118390996, 566, 571) Martin Luther King Jr. Memorial\n",
            "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
            "(451313080118390996, 157, 161) Southern Christian Leadership Conference\n",
            "(451313080118390996, 6, 9) Michael King Jr.\n",
            "(451313080118390996, 238, 241) Civil Rights Act\n",
            "(451313080118390996, 244, 247) Voting Rights Act\n",
            "(451313080118390996, 252, 255) Fair Housing Act\n",
            "(451313080118390996, 314, 317) J. Edgar Hoover\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spacy Custom Components - changes the doc object along the spacy pipeline\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"Britain is a place. Mary is a doctor.\")"
      ],
      "metadata": {
        "id": "AOjYlULJSra9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print (ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ai9hiAVV0B_",
        "outputId": "8d899adf-2d32-4fb5-a7d7-84f7d18cff2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Britain GPE\n",
            "Mary PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Say we want LOC label instead of the GPE label\n",
        "\n",
        "from spacy.language import Language\n",
        "\n",
        "@Language.component(\"remove_gpe\")\n",
        "\n",
        "def remove_gpe(doc):\n",
        "  original_ents = list(doc.ents)\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ == \"GPE\":\n",
        "      original_ents.remove(ent)\n",
        "  doc.ents = original_ents\n",
        "  return (doc)"
      ],
      "metadata": {
        "id": "tYCjpJkYWWE0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe(\"remove_gpe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ6wTFM7bru8",
        "outputId": "039491c4-be93-4a8a-e632-b4dce90a8d48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.remove_gpe(doc)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.analyze_pipes() #remove_gpe pipe would be added"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwLVNkgCb7Pb",
        "outputId": "3c6564c3-f06b-4d9f-8e9d-0fd3580a1466"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False},\n",
              "  'remove_gpe': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': [],\n",
              "  'remove_gpe': []},\n",
              " 'attrs': {'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
              "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the change in pipeline\n",
        "\n",
        "doc = nlp(\"Britain is a place. Mary is a doctor.\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jMYg0_nclyA",
        "outputId": "276a478d-7b38-4cc6-cf46-ca617220dc39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4tuhhW6PtRSI"
      }
    }
  ]
}